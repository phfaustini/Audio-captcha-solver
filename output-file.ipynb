{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório do projeto - Mineração de Dados\n",
    "\n",
    "##  Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução\n",
    "\n",
    "Este trabalho estuda técnicas de mineração de dados para classificar áudio. Em específico, o universo a ser classificado consiste em dez caracteres: 6, 7, a, b, c, d, h, m, n, x. Cada arquivo de áudio, chamado de _captcha_, contém 4 caracteres, podendo haver caracteres repetidos ou não. O objetivo é identificar quais caracteres estão presentes nos _captchas_. A classificação de um _captcha_ é considerada sucesso quando **todos** os seus quatro caracteres são corretamente identificados. Caso haja uma ou mais caracteres erroneamente classificados em um _captcha_, a classificação é considerada errada para aquele _captcha_.\n",
    "\n",
    "### Ferramentas necessárias para a reprodução:\n",
    "\n",
    "Para este trabalho foram utilizadas as ferramentas mencionadas abaixo. É importante prestar atenção nas versões das mesmas, quando indicadas.\n",
    "\n",
    "#### Programas e ambientes\n",
    "- FFMPEG\n",
    "- Anaconda (Python>=3.5) \n",
    "- Linux\n",
    "\n",
    "#### Bibliotecas python\n",
    "-  numpy>=1.13.3\n",
    "-  pandas>=0.20.3\n",
    "-  scikit-learn>=0.19.1\n",
    "-  scipy==1.1.0 \n",
    "-  librosa>=0.6.1\n",
    "-  matplotlib>=1.5.3\n",
    "\n",
    "\n",
    "Numpy e Pandas são bibliotecas criadas para manipular vetores de uma forma mais otimizada e rica em informação em relação à classe _list_ da biblioteca padrão do Python. Scikit-learn é uma biblioteca que implementa diversos algoritmos de mineração de dados, bem como técnicas de transformação e pré-processamento. Scipy é uma biblioteca usada para computação científica. Matplotlib fornece funções para plotar imagens e gráficos. Por fim, librosa é uma biblioteca para manipulação de áudio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from math import fabs\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from spectrum import get_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "TRAINING_OUTPUT = 'output_training/'\n",
    "TRAINING_AUDIO_CAPTCHA_FOLDERS = [TRAINING_OUTPUT+i for i in os.listdir(TRAINING_OUTPUT)]\n",
    "TRAINING_AUDIO_FILENAMES = [] # -> <number>_<digit>.wav\n",
    "for folder in TRAINING_AUDIO_CAPTCHA_FOLDERS:\n",
    "    for f in os.listdir(folder):\n",
    "        TRAINING_AUDIO_FILENAMES.append(folder+'/'+f)\n",
    "\n",
    "TEST_OUTPUT = 'output_test/'\n",
    "TEST_AUDIO_CAPTCHA_FOLDERS = [TEST_OUTPUT+i for i in os.listdir(TEST_OUTPUT)]\n",
    "\n",
    "TEST_AUDIO_FILENAMES = [] # -> <number>_<digit>.wav\n",
    "for folder in TEST_AUDIO_CAPTCHA_FOLDERS:\n",
    "    for f in os.listdir(folder):\n",
    "        TEST_AUDIO_FILENAMES.append(folder+'/'+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_filename: str, path: str) -> pd.core.series.Series:\n",
    "    data, _ = librosa.core.load(path +'/'+ audio_filename, sr=SAMPLE_RATE)\n",
    "\n",
    "    label = audio_filename.split('.')[0].split('-')[-1]\n",
    "\n",
    "    feature1_raw = librosa.feature.mfcc(data, sr=SAMPLE_RATE, n_mfcc=40)\n",
    "    \n",
    "    feature1 = np.array([list(map(fabs, sublist)) for sublist in feature1_raw]) # Tudo positivo\n",
    "\n",
    "    npstd = np.std(feature1, axis=1)\n",
    "    npmedian = np.median(feature1, axis=1)\n",
    "    feature1_flat = np.hstack((npmedian, npstd))\n",
    "\n",
    "    feature2 = librosa.feature.zero_crossing_rate(y=data)\n",
    "    feature2_flat = feature2.size\n",
    "\n",
    "    feature3 = librosa.feature.spectral_rolloff(data)\n",
    "    feature3_flat = np.hstack((np.median(feature3), np.std(feature3)))\n",
    "\n",
    "    feature4 = librosa.feature.spectral_centroid(data)\n",
    "    feature4_flat = np.hstack((np.median(feature4), np.std(feature4)))\n",
    "    \n",
    "    feature5 = librosa.feature.spectral_contrast(data)\n",
    "    feature5_flat = np.hstack((np.median(feature5), np.std(feature5)))\n",
    "\n",
    "    feature6 = librosa.feature.spectral_bandwidth(data)\n",
    "    feature6_flat = np.hstack((np.median(feature6), np.std(feature6)))\n",
    "\n",
    "    feature7 = librosa.feature.tonnetz(data)\n",
    "    feature7_flat = np.hstack((np.median(feature7), np.std(feature7)))\n",
    "\n",
    "\n",
    "    feature8_flat = get_spectrum(data)\n",
    "\n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    #librosa.display.specshow(feature1, x_axis='time')\n",
    "    #plt.colorbar()\n",
    "    #plt.title(label)\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    features = pd.Series(np.hstack((feature1_flat, feature2_flat, feature3_flat, \n",
    "                                    feature4_flat, feature5_flat, feature6_flat, \n",
    "                                    feature7_flat, feature8_flat, label)))\n",
    "    return features\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train() -> tuple:\n",
    "    X_train_raw = []\n",
    "    y_train = []\n",
    "    for sample in TRAINING_AUDIO_FILENAMES:\n",
    "        folder = '/'.join(sample.split('/')[0:2])\n",
    "        filename = sample.split('/')[-1]\n",
    "        obj = extract_features(filename, folder)\n",
    "        d = obj[0:obj.size - 1]\n",
    "        l = obj[obj.size - 1]\n",
    "        X_train_raw.append(d)\n",
    "        y_train.append(l)\n",
    "\n",
    "    # Normalisar\n",
    "    std_scale = preprocessing.StandardScaler().fit(X_train_raw) \n",
    "    X_train = std_scale.transform(X_train_raw)\n",
    "    return X_train, np.array(y_train), std_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(X_train: np.ndarray, y_train: np.ndarray, std_scale: preprocessing.data.StandardScaler):\n",
    "    accuracy1NN = 0\n",
    "    accuracySVM = 0\n",
    "    accuracyTotal = 0\n",
    "    total1NN = 0\n",
    "    totalSVM = 0\n",
    "    total = 0\n",
    "    for folder in TEST_AUDIO_CAPTCHA_FOLDERS:\n",
    "        correct1NN = 0\n",
    "        correctSVM = 0\n",
    "        correct = 0\n",
    "        for filename in os.listdir(folder):\n",
    "            obj = extract_features(filename, folder)\n",
    "            y_test = obj[obj.size - 1]\n",
    "            X_test_raw = [obj[0:obj.size - 1]]\n",
    "            X_test = std_scale.transform(X_test_raw) # Normalisar\n",
    "            \n",
    "            neigh1 = KNeighborsClassifier(n_neighbors=1)    #D, N\n",
    "            y_pred_1nn = neigh1.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "            clf = SVC()\n",
    "            y_pred_svm = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "            y_pred = y_pred_svm[0]\n",
    "            if y_pred_svm[0] == 'd' or y_pred_svm[0] == 'm': # SVM erra muito essas\n",
    "                y_pred = y_pred_1nn[0]\n",
    "            if y_pred_1nn[0] == 'd' or y_pred_1nn[0] == 'm':\n",
    "                y_pred = y_pred_1nn[0]\n",
    "\n",
    "            if y_pred == y_test:\n",
    "                correct+=1\n",
    "                total+=1\n",
    "                print('V '+y_test+\" \"+y_pred[0])\n",
    "            else:\n",
    "                print('E '+y_test+\" \"+y_pred[0])        \n",
    "            \n",
    "        if correct == 4:\n",
    "            accuracyTotal+=1\n",
    "\n",
    "    number_of_folders = len(TEST_AUDIO_CAPTCHA_FOLDERS)\n",
    "    number_of_characters = len(TEST_AUDIO_FILENAMES)\n",
    "    print(\"Acuracia (captcha) = {0:.2f}%\".format((accuracyTotal / number_of_folders)*100))\n",
    "    print(\"Acuracia (caracteres) = {0:.2f}%\".format((total / number_of_characters)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_captcha():\n",
    "    X_train, y_train, std_scale = train()\n",
    "    test(X_train, y_train, std_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    break_captcha()\n",
    "    #a=important_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
