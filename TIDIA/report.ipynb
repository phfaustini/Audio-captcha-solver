{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório do projeto - Mineração de Dados\n",
    "\n",
    "##  Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução\n",
    "\n",
    "Este trabalho estuda técnicas de mineração de dados para classificar áudio. Em específico, o universo a ser classificado consiste em dez caracteres: 6, 7, a, b, c, d, h, m, n, x. Cada arquivo de áudio, chamado de _captcha_, contém 4 caracteres, podendo haver caracteres repetidos ou não. O objetivo é identificar quais caracteres estão presentes nos _captchas_. A classificação de um _captcha_ é considerada sucesso quando **todos** os seus quatro caracteres são corretamente identificados. Caso haja uma ou mais caracteres erroneamente classificados em um _captcha_, a classificação é considerada errada para aquele _captcha_.\n",
    "\n",
    "### Ferramentas necessárias para a reprodução:\n",
    "\n",
    "Para este trabalho foram utilizadas as ferramentas mencionadas abaixo. É importante prestar atenção nas versões das mesmas, quando indicadas.\n",
    "\n",
    "#### Programas e ambientes\n",
    "- FFMPEG\n",
    "- Anaconda (Python>=3.5) \n",
    "- Linux\n",
    "\n",
    "#### Bibliotecas python\n",
    "-  numpy>=1.13.3\n",
    "-  pandas>=0.20.3\n",
    "-  scikit-learn>=0.19.1\n",
    "-  scipy==1.1.0 \n",
    "-  librosa>=0.6.1\n",
    "-  matplotlib>=1.5.3\n",
    "-  Sox (conda install -c conda-forge sox)\n",
    "\n",
    "\n",
    "Numpy e Pandas são bibliotecas criadas para manipular vetores de uma forma mais otimizada e rica em informação em relação à classe _list_ da biblioteca padrão do Python. Scikit-learn é uma biblioteca que implementa diversos algoritmos de mineração de dados, bem como técnicas de transformação e pré-processamento. Scipy é uma biblioteca usada para computação científica. Matplotlib fornece funções para plotar imagens e gráficos. Por fim, librosa é uma biblioteca para manipulação de áudio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise exploratória\n",
    "\n",
    "A primeira tarefa é segmentar os _captchas_. Como cada _captcha_ contém quatro caracteres, a ideia é gerar quatro arquivos .wav, um para cada caractere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import os\n",
    "from pysndfx import AudioEffectsChain\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "fx = (\n",
    "    AudioEffectsChain()\n",
    "    .limiter(20.0)\n",
    "    .lowpass(2500, 2)\n",
    "    .highpass(100)\n",
    "    .equalizer(300, db=15.0)\n",
    ")\n",
    "\n",
    "SHOW_PLOTS = False\n",
    "\n",
    "def remove_until(l, until):\n",
    "    t = list(l)\n",
    "    n = len(t)\n",
    "    while n > until:\n",
    "        m = np.full((n, n), np.inf)\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                m[i,j] = t[j] - t[i]\n",
    "\n",
    "        to_adapt, to_remove = np.unravel_index(m.argmin(), m.shape)\n",
    "        t[to_adapt] = (t[to_adapt]+t[to_remove])/2\n",
    "        del t[to_remove]\n",
    "        n = len(t)\n",
    "    return t\n",
    "\n",
    "def extract_labels(filename):\n",
    "    return os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "def trim(filename, output):\n",
    "    y, sr = librosa.load(filename)\n",
    "\n",
    "    FOLGA = int(sr)\n",
    "    N_SLICES = 4\n",
    "\n",
    "    y = librosa.to_mono(y)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y, indexes = librosa.effects.trim(y, top_db=24, frame_length=2)\n",
    "    fxy = fx(y)\n",
    "    fxy[np.abs(fxy) < 0.5] = 0\n",
    "\n",
    "    peaks, _ = find_peaks(fxy, height=0.5, distance=sr)\n",
    "    peaks = remove_until(peaks, N_SLICES)\n",
    "\n",
    "    if SHOW_PLOTS:\n",
    "        peak_times = librosa.samples_to_time(peaks)\n",
    "        plt.title(filename)\n",
    "        librosa.display.waveplot(fxy)\n",
    "        librosa.display.waveplot(y)\n",
    "        plt.vlines(peak_times, -1, 1, color='red', linestyle='--',linewidth=8, alpha=0.9, label='Segment boundaries')\n",
    "        plt.show()\n",
    "\n",
    "    labels = extract_labels(filename)\n",
    "\n",
    "    if not os.path.exists('%s/%s' % (output, labels)):\n",
    "        os.mkdir('%s/%s' % (output, labels))\n",
    "\n",
    "    for i in range(N_SLICES):\n",
    "        if(i >= len(peaks)):\n",
    "            continue\n",
    "        p = peaks[i]\n",
    "        left = int(round(max(0, p - FOLGA)))\n",
    "        right = int(round(min(p + FOLGA, len(y)-1)))\n",
    "        audio = y[left:right]\n",
    "        if(np.any(audio)):\n",
    "            _, [l,r] = librosa.effects.trim(audio, top_db=12, frame_length=2)\n",
    "            l = int(round(max(0, l - FOLGA//4)))\n",
    "            r = int(round(min(r + FOLGA//4, len(y)-1)))\n",
    "            audio_trim = audio[l:r]\n",
    "            audio_trim = librosa.util.normalize(audio_trim)\n",
    "            librosa.output.write_wav('%s/%s/%d-%s.wav' % (output, labels, i, labels[i]), audio_trim, sr=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um primeiro momento, é necessário criar a estrutura de pastas para que os algoritmos de mineração de dados atuem. É **assumido** que haja, no atual diretório, uma pasta chamada *fase\\_1/base\\_treinamento\\_I* e uma pasta chamada *fase\\_1\\_base_validacao\\_I*. Dentro dessas pastas, há uma pasta para cada _captcha_ contendo um arquivo .wav, cujo nome são os quatro caracteres que compõem o _captcha_ na ordem em que aparecem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FOLDER = './fase_1/base_treinamento_I/'\n",
    "TEST_FOLDER = './fase_1/base_validacao_I/'\n",
    "TRAINING_OUTPUT = './output_training/'\n",
    "TEST_OUTPUT = './output_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_folder_structure():\n",
    "    \"\"\"Cria a estrutura de pastas\n",
    "    necessaria, caso ela nao exista.\n",
    "    Em seguida, faz a segmentacao.\n",
    "\n",
    "    As pastas TEST_OUTPUT e TRAINING_OUTPUT\n",
    "    contem os captchas segmentados.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(TRAINING_OUTPUT):\n",
    "        os.mkdir(TRAINING_OUTPUT)\n",
    "    if not os.path.exists(TEST_OUTPUT):\n",
    "        os.mkdir(TEST_OUTPUT)\n",
    "\n",
    "    for f in os.listdir(TRAINING_FOLDER):\n",
    "        filename = os.path.join(TRAINING_FOLDER, f)\n",
    "        audios = trim(filename, TRAINING_OUTPUT)\n",
    "    for f in os.listdir(TEST_FOLDER):\n",
    "        filename = os.path.join(TEST_FOLDER, f)\n",
    "        audios = trim(filename, TEST_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, a estrutura de pastas necessária para a classificação é montada. Os arquivos segmentados ficam nas pastas *output\\_training* e *output\\_test*. Dentro de cada pasta há um arquivo .wav para cada caractere identificado na segmentação. O nome de cada arquivo é *ordem\\-caractere.wav*. Por exemplo, se o terceiro caractere de um dado _captcha_ for a letra \"d\", o nome do arquivo correspondente a ele será *3-d.wav*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import fabs\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "TRAINING_OUTPUT = 'output_training/'\n",
    "TRAINING_AUDIO_CAPTCHA_FOLDERS = [TRAINING_OUTPUT+i for i in os.listdir(TRAINING_OUTPUT)]\n",
    "TRAINING_AUDIO_FILENAMES = [] # -> <number>_<digit>.wav\n",
    "for folder in TRAINING_AUDIO_CAPTCHA_FOLDERS:\n",
    "    for f in os.listdir(folder):\n",
    "        TRAINING_AUDIO_FILENAMES.append(folder+'/'+f)\n",
    "\n",
    "TEST_OUTPUT = 'output_test/'\n",
    "TEST_AUDIO_CAPTCHA_FOLDERS = [TEST_OUTPUT+i for i in os.listdir(TEST_OUTPUT)]\n",
    "\n",
    "TEST_AUDIO_FILENAMES = [] # -> <number>_<digit>.wav\n",
    "for folder in TEST_AUDIO_CAPTCHA_FOLDERS:\n",
    "    for f in os.listdir(folder):\n",
    "        TEST_AUDIO_FILENAMES.append(folder+'/'+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir é necessário extrair atributos da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysndfx import AudioEffectsChain\n",
    "import numpy as np\n",
    "\n",
    "def make_chain(low, high):\n",
    "    return (AudioEffectsChain()\n",
    "        .lowpass(high, 3.0)\n",
    "        .highpass(low, 3.0))\n",
    "\n",
    "sb = make_chain(20, 60)\n",
    "b = make_chain(60, 250)\n",
    "lm = make_chain(250, 500)\n",
    "m = make_chain(500, 2000)\n",
    "um = make_chain(2000, 4000)\n",
    "p = make_chain(4000, 6000)\n",
    "br = make_chain(6000, 20000)\n",
    "\n",
    "specs = [sb,b,lm,m,um,p,br]\n",
    "\n",
    "\n",
    "def get_spectrum(audio):\n",
    "    return [np.mean(np.abs(spectrum(audio))) for spectrum in specs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_filename: str, path: str) -> pd.core.series.Series:\n",
    "    data, _ = librosa.core.load(path +'/'+ audio_filename, sr=SAMPLE_RATE)\n",
    "\n",
    "    label = audio_filename.split('.')[0].split('-')[-1]\n",
    "\n",
    "    feature1_raw = librosa.feature.mfcc(data, sr=SAMPLE_RATE, n_mfcc=40)\n",
    "    \n",
    "    feature1 = np.array([list(map(fabs, sublist)) for sublist in feature1_raw]) # Tudo positivo\n",
    "\n",
    "    npstd = np.std(feature1, axis=1)\n",
    "    npmedian = np.median(feature1, axis=1)\n",
    "    feature1_flat = np.hstack((npmedian, npstd))\n",
    "\n",
    "    feature2 = librosa.feature.zero_crossing_rate(y=data)\n",
    "    feature2_flat = feature2.size\n",
    "\n",
    "    feature3 = librosa.feature.spectral_rolloff(data)\n",
    "    feature3_flat = np.hstack((np.median(feature3), np.std(feature3)))\n",
    "\n",
    "    feature4 = librosa.feature.spectral_centroid(data)\n",
    "    feature4_flat = np.hstack((np.median(feature4), np.std(feature4)))\n",
    "    \n",
    "    feature5 = librosa.feature.spectral_contrast(data)\n",
    "    feature5_flat = np.hstack((np.median(feature5), np.std(feature5)))\n",
    "\n",
    "    feature6 = librosa.feature.spectral_bandwidth(data)\n",
    "    feature6_flat = np.hstack((np.median(feature6), np.std(feature6)))\n",
    "\n",
    "    feature7 = librosa.feature.tonnetz(data)\n",
    "    feature7_flat = np.hstack((np.median(feature7), np.std(feature7)))\n",
    "\n",
    "\n",
    "    feature8_flat = get_spectrum(data)\n",
    "\n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    #librosa.display.specshow(feature1, x_axis='time')\n",
    "    #plt.colorbar()\n",
    "    #plt.title(label)\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    features = pd.Series(np.hstack((feature1_flat, feature2_flat, feature3_flat, \n",
    "                                    feature4_flat, feature5_flat, feature6_flat, \n",
    "                                    feature7_flat, feature8_flat, label)))\n",
    "    return features\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metodologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train() -> tuple:\n",
    "    X_train_raw = []\n",
    "    y_train = []\n",
    "    for sample in TRAINING_AUDIO_FILENAMES:\n",
    "        folder = '/'.join(sample.split('/')[0:2])\n",
    "        filename = sample.split('/')[-1]\n",
    "        obj = extract_features(filename, folder)\n",
    "        d = obj[0:obj.size - 1]\n",
    "        l = obj[obj.size - 1]\n",
    "        X_train_raw.append(d)\n",
    "        y_train.append(l)\n",
    "\n",
    "    # Normalisar\n",
    "    std_scale = preprocessing.StandardScaler().fit(X_train_raw) \n",
    "    X_train = std_scale.transform(X_train_raw)\n",
    "    return X_train, np.array(y_train), std_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(X_train: np.ndarray, y_train: np.ndarray, std_scale: preprocessing.data.StandardScaler):\n",
    "    accuracy1NN = 0\n",
    "    accuracySVM = 0\n",
    "    accuracyTotal = 0\n",
    "    total1NN = 0\n",
    "    totalSVM = 0\n",
    "    total = 0\n",
    "    for folder in TEST_AUDIO_CAPTCHA_FOLDERS:\n",
    "        correct1NN = 0\n",
    "        correctSVM = 0\n",
    "        correct = 0\n",
    "        for filename in os.listdir(folder):\n",
    "            obj = extract_features(filename, folder)\n",
    "            y_test = obj[obj.size - 1]\n",
    "            X_test_raw = [obj[0:obj.size - 1]]\n",
    "            X_test = std_scale.transform(X_test_raw) # Normalisar\n",
    "            \n",
    "            neigh1 = KNeighborsClassifier(n_neighbors=1)    #D, N\n",
    "            y_pred_1nn = neigh1.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "            clf = SVC()\n",
    "            y_pred_svm = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "            y_pred = y_pred_svm[0]\n",
    "            if y_pred_svm[0] == 'd' or y_pred_svm[0] == 'm': # SVM erra muito essas\n",
    "                y_pred = y_pred_1nn[0]\n",
    "            if y_pred_1nn[0] == 'd' or y_pred_1nn[0] == 'm':\n",
    "                y_pred = y_pred_1nn[0]\n",
    "\n",
    "            if y_pred == y_test:\n",
    "                correct+=1\n",
    "                total+=1\n",
    "                print('V '+y_test+\" \"+y_pred[0])\n",
    "            else:\n",
    "                print('E '+y_test+\" \"+y_pred[0])        \n",
    "            \n",
    "        if correct == 4:\n",
    "            accuracyTotal+=1\n",
    "\n",
    "    number_of_folders = len(TEST_AUDIO_CAPTCHA_FOLDERS)\n",
    "    number_of_characters = len(TEST_AUDIO_FILENAMES)\n",
    "    print(\"Acuracia (captcha) = {0:.2f}%\".format((accuracyTotal / number_of_folders)*100))\n",
    "    print(\"Acuracia (caracteres) = {0:.2f}%\".format((total / number_of_characters)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_captcha():\n",
    "    X_train, y_train, std_scale = train()\n",
    "    test(X_train, y_train, std_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "break_captcha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comentários finais\n",
    "\n",
    "- Dificuldades encontradas\n",
    "\n",
    "- Ideias que não foram exploradas e a razão"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
